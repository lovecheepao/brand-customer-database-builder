# -*- coding: utf-8 -*-
"""tarteæœˆæ¬¡å£²ä¸Šé›†è¨ˆ.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/gist/lovecheepao/af0999702e960cd84ce51f03708e3407/tarte.ipynb

### ğŸ§­ ä½¿ç”¨æ‰‹é †

1. ã¾ãšã€å¯¾è±¡ã®æœŸé–“ã§çµã‚Šè¾¼ã‚“ã ä¸‹è¨˜â‘ ã€œâ‘£ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”¨æ„ã—ã€
ã€Œtarteäº‹æ¥­ç®¡ç†èª²2023ï¼å£²ä¸Šç­‰ãƒ‡ãƒ¼ã‚¿ã€ãƒ•ã‚©ãƒ«ãƒ€ã®ç›´ä¸‹ã«æ ¼ç´ã—ã¦ãã ã•ã„ã€‚
2. ä¸Šã‹ã‚‰é †ã«ã‚»ãƒ«ã®å·¦å´ã®ã€Œâ–¶ï¸ã€ãƒãƒ¼ã‚¯ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ã€ã‚³ãƒ¼ãƒ‰ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚(ä¸€ã¤ã®ã‚»ãƒ«ãŒçµ‚äº†ã—ã¦ã‹ã‚‰æ¬¡ã®ã‚’æŠ¼ã—ã¦ãã ã•ã„ï¼‰
3. å„ã‚¹ãƒ†ãƒƒãƒ—ã§æŒ‡å®šã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
4. æœ€å¾Œã¾ã§å®Ÿè¡Œã™ã‚‹ã¨ã€ãƒ‡ãƒ¼ã‚¿ï¼ˆé¡§å®¢ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€æ³¨æ–‡åˆ¥é›†è¨ˆã€å•†å“å®Ÿç¸¾ï¼‰ãŒè‡ªå‹•ã§Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã€Œtarte å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã€ã«è¿½åŠ ã•ã‚Œã¾ã™ã€‚

---

### ğŸ“ å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§

| ãƒ•ã‚¡ã‚¤ãƒ«å              | ãƒ‡ãƒ¼ã‚¿å†…å®¹         | æ ¼ç´ or å‡ºåŠ›å ´æ‰€          |
| ------------------ | ----------- | ----------- |
| â‘ sales.csv          | ECã®æ³¨æ–‡æ˜ç´° | BOã®æ³¨æ–‡æ¤œç´¢ã§å‡ºåŠ›ã€€â€»ã‚­ãƒ£ãƒ³ã‚»ãƒ«/è¿”å“ æœªè¨˜å…¥ã§æŠ½å‡º       |
| â‘¡sales\_history.csv | ECã®æ³¨æ–‡æ˜ç´°ï¼ˆå¹´é½¢ä»˜ãï¼‰ | BOã®è³¼å…¥ãƒ’ã‚¹ãƒˆãƒªãƒ¼ã§å‡ºåŠ›   |
| â‘¢customer.csv       | ECã®ä¼šå“¡ç•ªå·ã¨ä¼šå“¡ç™»éŒ²æ—¥ |BOã®ä¼šå“¡æƒ…å ±ã§å‡ºåŠ›   |
| ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å‰²å¼•ãƒã‚¹ã‚¿.xlsx | ECã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å‰²å¼•ç‡ä¸€è¦§ |ã€Œtarteäº‹æ¥­ç®¡ç†èª²2023/å£²ä¸Šç­‰ãƒ‡ãƒ¼ã‚¿ã€ç›´ä¸‹ã«ã‚ã‚Šã¾ã™ |
| â‘£ZC870 æ˜ç´°å‡ºåŠ›.xlsx       | åº—èˆ—ã®æ³¨æ–‡æ˜ç´° | KOMPASã®æ˜ç´°å‡ºåŠ›ã§å‡ºåŠ›   |
| category.csv       | ã‚«ãƒ†ã‚´ãƒªãƒ¼ãªã©å•†å“æƒ…å ± | ã€Œtarteäº‹æ¥­ç®¡ç†èª²2023/å£²ä¸Šç­‰ãƒ‡ãƒ¼ã‚¿ã€ç›´ä¸‹ã«ã‚ã‚Šã¾ã™   |

---

### âš ï¸ æ³¨æ„äº‹é …

* ãƒ•ã‚¡ã‚¤ãƒ«åã‚„å½¢å¼ãŒç•°ãªã‚‹å ´åˆã¯ã€ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚
* ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¯ã€**æ±‚ã‚ã‚‰ã‚ŒãŸã‚¿ã‚¤ãƒŸãƒ³ã‚°ã§**è¡Œã£ã¦ãã ã•ã„ã€‚

# **ã‚¹ãƒ†ãƒƒãƒ—1:** **å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼†Googleãƒ‰ãƒ©ã‚¤ãƒ–ã«ãƒã‚¦ãƒ³ãƒˆ**
"""

# âœ… å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
!pip install --upgrade gspread gspread_dataframe japanize_matplotlib --quiet

# âœ… èªè¨¼ï¼†ãƒ‰ãƒ©ã‚¤ãƒ–ãƒã‚¦ãƒ³ãƒˆ
from google.colab import drive
drive.mount('/content/drive')

# âœ… Googleã‚¢ã‚«ã‚¦ãƒ³ãƒˆèªè¨¼ â†ã“ã‚Œã‚’è¿½åŠ ï¼
from google.colab import auth
auth.authenticate_user()

# âœ… èªè¨¼ã¨APIæ“ä½œ
import gspread
from google.auth import default
from gspread_dataframe import set_with_dataframe, get_as_dataframe
creds, _ = default()
gc = gspread.authorize(creds)

# âœ… ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªç§»å‹•ï¼ˆãƒ‰ãƒ©ã‚¤ãƒ–å†…ã®ä»»æ„ãƒ•ã‚©ãƒ«ãƒ€ã¸ï¼‰
import os
os.chdir('/content/drive/MyDrive/')

# âœ… åˆ†æç”¨ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import pandas as pd
import matplotlib.pyplot as plt
import japanize_matplotlib
import seaborn as sns
from datetime import date

# âœ… æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆè¨­å®šï¼ˆSeabornï¼‰
sns.set(font=['IPAexGothic'])

# âœ… ãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ãªã©ã§ä½¿ã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from google.colab import files

"""# **ã‚¹ãƒ†ãƒƒãƒ—2:** **ECã®æ³¨æ–‡æ˜ç´°ã‚’æ³¨æ–‡ã€å•†å“ã”ã¨ã«é›†è¨ˆã™ã‚‹**

âœ…â‘ sales.csv â‘¡sales_history.csv â‘¢category.csv â‘£ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³å‰²å¼•ãƒã‚¹ã‚¿.xlsxã‚’è¤‡æ•°é¸æŠã—ã¦ã¾ã¨ã‚ã¦ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„
"""

# ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded = files.upload()
uploaded_files = list(uploaded.keys())

# ãƒ•ã‚¡ã‚¤ãƒ«åã‚’è‡ªå‹•ç‰¹å®š
sales_file = next((f for f in uploaded_files if f.startswith('sales') and 'history' not in f), None)
members_file = next((f for f in uploaded_files if f.startswith('sales_history')), None)
category_file = next((f for f in uploaded_files if f.startswith('category')), None)
campaign_file = next((f for f in uploaded_files if f.startswith('ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³')), None)

assert sales_file and members_file and category_file and campaign_file, "å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

# å£²ä¸Šãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ãƒ»åŠ å·¥
sd = pd.read_csv(sales_file, encoding='cp932')
sd['æ³¨æ–‡æ—¥'] = pd.to_datetime(sd['æ³¨æ–‡æ—¥'])
sd = sd[(sd['ç¨æŠœå˜ä¾¡'] > 0) & (sd['æ•°é‡'] > 0)]
sd['å•†å“ç¬¦å·'] = sd['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str).str[:4].str.strip()
sd['ç¨æŠœåˆè¨ˆé‡‘é¡'] = sd['æ•°é‡'] * sd['ç¨æŠœå˜ä¾¡']

# ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°ãƒã‚¹ã‚«ãƒ©åˆ†æ
def analyze_tubing_crosssell_detail(sd, product_code_travel='TRHM001', product_code_full='TRHL001'):
    tubing_codes = [product_code_travel, product_code_full]
    tubing_df = sd[sd['å•†å“ã‚³ãƒ¼ãƒ‰'].isin(tubing_codes)].copy()
    first_purchase_dates = tubing_df.groupby('ä¼šå“¡ç•ªå·')['æ³¨æ–‡æ—¥'].min().reset_index()
    return first_purchase_dates, tubing_codes

first_purchase_dates, tubing_codes = analyze_tubing_crosssell_detail(sd)

# ä¼šå“¡æƒ…å ±ã‚’ãƒãƒ¼ã‚¸
members = pd.read_csv(members_file, encoding='cp932', skiprows=5, on_bad_lines='skip')
members = members[['ä¼šå“¡ç•ªå·', 'å¹´é½¢']].drop_duplicates()
sd = pd.merge(sd, members, on='ä¼šå“¡ç•ªå·', how='left')
sd['å¹´é½¢'] = pd.to_numeric(sd['å¹´é½¢'], errors='coerce').astype('Int64')

#å¹´ä»£å¤‰æ›
def convert_to_age_group(age):
    if pd.isnull(age) or age < 10 or age > 130:
        return 'ä¸æ˜'
    if age < 70:
        return f"{(age // 10) * 10}ä»£"
    return '70ä»£ä»¥ä¸Š'

sd['å¹´ä»£'] = sd['å¹´é½¢'].apply(convert_to_age_group)

# å‰²å¼•è¨ˆç®—
df_discount = pd.read_excel(campaign_file)
df_discount['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³é–‹å§‹æ—¥'] = pd.to_datetime(df_discount['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³é–‹å§‹æ—¥'])
df_discount['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³çµ‚äº†æ—¥'] = pd.to_datetime(df_discount['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³çµ‚äº†æ—¥'])

percentage_discounts = df_discount[df_discount['å‰²å¼•ç‡'] < 1]
fixed_discounts = df_discount[df_discount['å‰²å¼•ç‡'] >= 1]

sd['å‰²å¼•ç‡'] = 0.0
sd['ç¨æŠœå‰²å¼•å¾Œå˜ä¾¡'] = sd['ç¨æŠœå˜ä¾¡']
sd['ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'] = sd['ç¨æŠœåˆè¨ˆé‡‘é¡']

# å‰²åˆå‰²å¼•ã®é©ç”¨ï¼ˆå•†å“ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ï¼‰
for _, row in percentage_discounts.iterrows():
    mask = (
        sd['é©ç”¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³'].astype(str).str.contains(str(row['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ID']), na=False) &
        (sd['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str) == str(row['å•†å“ã‚³ãƒ¼ãƒ‰'])) &  # å•†å“ã‚³ãƒ¼ãƒ‰åŒå£«ã§æ¯”è¼ƒ
        (sd['æ³¨æ–‡æ—¥'] >= row['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³é–‹å§‹æ—¥']) &
        (sd['æ³¨æ–‡æ—¥'] <= row['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³çµ‚äº†æ—¥'])
    )
    sd.loc[mask, 'å‰²å¼•ç‡'] = row['å‰²å¼•ç‡']

    # å‰²å¼•å¾Œé‡‘é¡ã‚’è¨ˆç®—
    sd.loc[mask, 'ç¨æŠœå‰²å¼•å¾Œå˜ä¾¡'] = sd.loc[mask, 'ç¨æŠœå˜ä¾¡'] * (1 - row['å‰²å¼•ç‡'])
    sd.loc[mask, 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'] = sd.loc[mask, 'æ•°é‡'] * sd.loc[mask, 'ç¨æŠœå‰²å¼•å¾Œå˜ä¾¡']

    # ç‰¹åˆ¥ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³è¿½åŠ å‰²å¼•
    target_rows = sd[mask]
    for order_no in target_rows['æ³¨æ–‡ç•ªå·'].unique():
        special_campaign = sd[
            (sd['æ³¨æ–‡ç•ªå·'] == order_no) &
            (sd['é©ç”¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³'].astype(str).str.contains('tarte-live230308cp', na=False))
        ]
        if not special_campaign.empty:
            additional_mask = (
                (sd['æ³¨æ–‡ç•ªå·'] == order_no) &
                (sd['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str) == str(row['å•†å“ã‚³ãƒ¼ãƒ‰']))
            )
            # è¿½åŠ å‰²å¼•ã‚’é©ç”¨
            sd.loc[additional_mask, 'å‰²å¼•ç‡'] += 0.10
            current_discount_rate = sd.loc[additional_mask, 'å‰²å¼•ç‡'].iloc[0]
            sd.loc[additional_mask, 'ç¨æŠœå‰²å¼•å¾Œå˜ä¾¡'] = sd.loc[additional_mask, 'ç¨æŠœå˜ä¾¡'] * (1 - current_discount_rate)
            sd.loc[additional_mask, 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'] = sd.loc[additional_mask, 'æ•°é‡'] * sd.loc[additional_mask, 'ç¨æŠœå‰²å¼•å¾Œå˜ä¾¡']

# tarte230824cp-a ã¨ tarte230824cp-b ä»¥å¤–ã®å®šé¡å‰²å¼•ã ã‘å‡¦ç†
fixed_discounts_exclude_ab = fixed_discounts[
    ~fixed_discounts['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ID'].isin(['tarte230824cp-a', 'tarte230824cp-b'])
]

for _, row in fixed_discounts_exclude_ab.iterrows():
    target_rows = sd[
        sd['é©ç”¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³'].astype(str).str.contains(str(row['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ID']), na=False) &
        (sd['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str) == str(row['å•†å“ã‚³ãƒ¼ãƒ‰'])) &
        (sd['æ³¨æ–‡æ—¥'] >= row['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³é–‹å§‹æ—¥']) &
        (sd['æ³¨æ–‡æ—¥'] <= row['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³çµ‚äº†æ—¥'])
    ]
    for order_no in target_rows['æ³¨æ–‡ç•ªå·'].unique():
        order_mask = sd['æ³¨æ–‡ç•ªå·'] == order_no
        total = sd.loc[order_mask, 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'].sum()
        if total > 0:
            ratio = sd.loc[order_mask, 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'] / total
            fixed_discount_amount = row['å‰²å¼•ç‡']
            sd.loc[order_mask, 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'] -= ratio * fixed_discount_amount

# tarte230824cp-a ã ã‘ã‚’æ³¨æ–‡å˜ä½ã§é‡è¤‡é©ç”¨ã—ãªã„ã‚ˆã†ã«å‡¦ç†
target_campaign_id = 'tarte230824cp-a'
applied_orders = set()

for _, row in fixed_discounts[fixed_discounts['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ID'] == target_campaign_id].iterrows():
    target_rows = sd[
        sd['é©ç”¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³'].astype(str).str.contains(str(row['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ID']), na=False) &
        (sd['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str) == str(row['å•†å“ã‚³ãƒ¼ãƒ‰'])) &
        (sd['æ³¨æ–‡æ—¥'] >= row['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³é–‹å§‹æ—¥']) &
        (sd['æ³¨æ–‡æ—¥'] <= row['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³çµ‚äº†æ—¥'])
    ]

    for order_no in target_rows['æ³¨æ–‡ç•ªå·'].unique():
        if order_no in applied_orders:
            continue  # ã™ã§ã«å‰²å¼•é©ç”¨æ¸ˆã¿ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—ï¼
        order_mask = sd['æ³¨æ–‡ç•ªå·'] == order_no
        total = sd.loc[order_mask, 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'].sum()
        if total > 0:
            ratio = sd.loc[order_mask, 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'] / total
            sd.loc[order_mask, 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'] -= ratio * row['å‰²å¼•ç‡']
        applied_orders.add(order_no)

# tarte230824cp-b ã ã‘ã‚’æ³¨æ–‡å˜ä½ã§é‡è¤‡é©ç”¨ã—ãªã„ã‚ˆã†ã«å‡¦ç†
target_campaign_id_b = 'tarte230824cp-b'
applied_orders_b = set()

for _, row in fixed_discounts[fixed_discounts['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ID'] == target_campaign_id_b].iterrows():
    target_rows = sd[
        sd['é©ç”¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³'].astype(str).str.contains(str(row['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ID']), na=False) &
        (sd['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str) == str(row['å•†å“ã‚³ãƒ¼ãƒ‰'])) &
        (sd['æ³¨æ–‡æ—¥'] >= row['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³é–‹å§‹æ—¥']) &
        (sd['æ³¨æ–‡æ—¥'] <= row['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³çµ‚äº†æ—¥'])
    ]

    for order_no in target_rows['æ³¨æ–‡ç•ªå·'].unique():
        if order_no in applied_orders_b:
            continue  # ã™ã§ã«å‰²å¼•é©ç”¨æ¸ˆã¿ãªã®ã§ã‚¹ã‚­ãƒƒãƒ—ï¼
        order_mask = sd['æ³¨æ–‡ç•ªå·'] == order_no
        total = sd.loc[order_mask, 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'].sum()
        if total > 0:
            ratio = sd.loc[order_mask, 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'] / total
            sd.loc[order_mask, 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'] -= ratio * row['å‰²å¼•ç‡']
        applied_orders_b.add(order_no)

# ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šå‰²å¼•é©ç”¨çŠ¶æ³ã®ç¢ºèª
print("å‰²å¼•é©ç”¨çŠ¶æ³:")
discount_applied = sd[sd['å‰²å¼•ç‡'] > 0]
if len(discount_applied) > 0:
    print(f"å‰²å¼•é©ç”¨ä»¶æ•°: {len(discount_applied):,}ä»¶")
    print(discount_applied[['æ³¨æ–‡ç•ªå·', 'å•†å“ã‚³ãƒ¼ãƒ‰', 'å•†å“ç¬¦å·', 'å‰²å¼•ç‡', 'ç¨æŠœå˜ä¾¡', 'ç¨æŠœå‰²å¼•å¾Œå˜ä¾¡']].head())
else:
    print("å‰²å¼•ãŒé©ç”¨ã•ã‚ŒãŸå•†å“ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚")

# ãƒ‡ãƒ¼ã‚¿é›†è¨ˆ
order_meta = sd[['æ³¨æ–‡ç•ªå·', 'æ³¨æ–‡æ—¥', 'ä¼šå“¡ç•ªå·', 'å¹´ä»£', 'æ³¨æ–‡è€…éƒ½é“åºœçœŒ', 'é©ç”¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³']].drop_duplicates(subset='æ³¨æ–‡ç•ªå·').copy()
order_meta['å¹´æœˆ'] = order_meta['æ³¨æ–‡æ—¥'].dt.to_period('M').astype(str)

# âœ… ãƒ©ã‚¤ãƒ–è³¼å…¥ãƒ•ãƒ©ã‚°ã‚’ä»˜ä¸ ãƒ©ã‚¤ãƒ–è³¼å…¥ãƒ•ãƒ©ã‚°ãŒ1ã®ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³IDã‚’æŠ½å‡º
live_campaigns = df_discount[df_discount['ãƒ©ã‚¤ãƒ–è³¼å…¥ãƒ•ãƒ©ã‚°'] == 1]['ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ID'].dropna().unique().tolist()

order_meta['ãƒ©ã‚¤ãƒ–è³¼å…¥ãƒ•ãƒ©ã‚°'] = 0

for campaign_id in live_campaigns:
    mask = order_meta['é©ç”¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³'].astype(str).str.contains(str(campaign_id), na=False)
    order_meta.loc[mask, 'ãƒ©ã‚¤ãƒ–è³¼å…¥ãƒ•ãƒ©ã‚°'] = 1

order_detail_summary = sd.groupby(['æ³¨æ–‡ç•ªå·', 'å•†å“ã‚³ãƒ¼ãƒ‰'], as_index=False).agg({
    'æ•°é‡': 'sum',
    'ç¨æŠœåˆè¨ˆé‡‘é¡': 'sum',
    'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡': 'sum'
})

order_detail_summary = pd.merge(order_detail_summary, order_meta, on='æ³¨æ–‡ç•ªå·', how='left')

# æœˆæ¬¡å®Ÿç¸¾ã§ã‚‚å•†å“ã‚³ãƒ¼ãƒ‰ãŒå¿…è¦ãªã®ã§è¿½åŠ 
monthly_category = order_detail_summary.groupby(['å¹´æœˆ', 'å•†å“ã‚³ãƒ¼ãƒ‰'], as_index=False).agg({
    'æ•°é‡': 'sum',
    'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡': 'sum'
})

# å•†å“ãƒã‚¹ã‚¿çµåˆï¼ˆå•†å“ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã§çµ±ä¸€ï¼‰
category_master = pd.read_csv(category_file, encoding='cp932')
category_master.columns = category_master.columns.str.strip()
category_master['å•†å“ç¬¦å·'] = category_master['å•†å“ç¬¦å·'].astype(str).str.strip()
category_master['å•†å“ã‚³ãƒ¼ãƒ‰'] = category_master['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str).str.strip()

# å•†å“ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ã®å•†å“ãƒã‚¹ã‚¿ã‚’ä½œæˆ
product_info_cols = ['å•†å“ã‚³ãƒ¼ãƒ‰', 'å•†å“å', 'ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼']
product_master_by_code = category_master[product_info_cols].drop_duplicates(subset='å•†å“ã‚³ãƒ¼ãƒ‰', keep='first')

# å•†å“ç¬¦å·æƒ…å ±ã‚’å•†å“ãƒã‚¹ã‚¿ã‹ã‚‰å–å¾—
symbol_master = category_master[['å•†å“ã‚³ãƒ¼ãƒ‰', 'å•†å“ç¬¦å·']].drop_duplicates(subset='å•†å“ã‚³ãƒ¼ãƒ‰', keep='first')

# order_detail_summaryã«å•†å“ç¬¦å·ã‚’è¿½åŠ 
order_detail_summary = pd.merge(order_detail_summary, symbol_master, on='å•†å“ã‚³ãƒ¼ãƒ‰', how='left')

# å•†å“æƒ…å ±ã‚’çµåˆ
order_detail_summary = pd.merge(order_detail_summary, product_master_by_code, on='å•†å“ã‚³ãƒ¼ãƒ‰', how='left')

# ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°åˆå›è³¼å…¥ãƒ•ãƒ©ã‚°ä»˜ä¸
order_detail_summary = pd.merge(
    order_detail_summary,
    first_purchase_dates.rename(columns={'æ³¨æ–‡æ—¥': 'ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°åˆå›è³¼å…¥æ—¥'}),
    on='ä¼šå“¡ç•ªå·',
    how='left'
)
order_detail_summary['ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°åˆå›è³¼å…¥ãƒ•ãƒ©ã‚°'] = (
    (order_detail_summary['å•†å“ç¬¦å·'].isin(['TRHM', 'TRHL'])) &
    (order_detail_summary['æ³¨æ–‡æ—¥'] == order_detail_summary['ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°åˆå›è³¼å…¥æ—¥'])
).astype(int)
order_detail_summary.drop(columns=['ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°åˆå›è³¼å…¥æ—¥'], inplace=True)

# ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°è³¼å…¥æƒ…å ±
tubing_orders = (
    sd[sd['å•†å“ã‚³ãƒ¼ãƒ‰'].isin(tubing_codes)]
    .groupby('æ³¨æ–‡ç•ªå·', as_index=False)['æ•°é‡']
    .sum()
    .rename(columns={'æ•°é‡': 'æ³¨æ–‡å†…ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°è³¼å…¥æœ¬æ•°'})
)
tubing_orders['æ³¨æ–‡å†…ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°è³¼å…¥å›æ•°'] = 1

order_detail_summary = pd.merge(
    order_detail_summary,
    tubing_orders[['æ³¨æ–‡ç•ªå·', 'æ³¨æ–‡å†…ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°è³¼å…¥å›æ•°', 'æ³¨æ–‡å†…ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°è³¼å…¥æœ¬æ•°']],
    on=['æ³¨æ–‡ç•ªå·'],
    how='left'
)

order_detail_summary['æ³¨æ–‡å†…ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°è³¼å…¥æœ¬æ•°'] = order_detail_summary.apply(
    lambda row: row['æ³¨æ–‡å†…ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°è³¼å…¥æœ¬æ•°'] if row['å•†å“ç¬¦å·'] in ['TRHM', 'TRHL'] else 0,
    axis=1
)
order_detail_summary['æ³¨æ–‡å†…ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°è³¼å…¥å›æ•°'] = order_detail_summary.apply(
    lambda row: row['æ³¨æ–‡å†…ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°è³¼å…¥å›æ•°'] if row['å•†å“ç¬¦å·'] in ['TRHM', 'TRHL'] else 0,
    axis=1
)

# æœˆæ¬¡å®Ÿç¸¾ã«ã‚‚å•†å“ã‚³ãƒ¼ãƒ‰ã§å•†å“æƒ…å ±ã‚’çµåˆ
monthly_category = pd.merge(monthly_category, symbol_master, on='å•†å“ã‚³ãƒ¼ãƒ‰', how='left')
monthly_category = pd.merge(monthly_category, product_master_by_code, on='å•†å“ã‚³ãƒ¼ãƒ‰', how='left')

# ã‚«ãƒ©ãƒ é †åºèª¿æ•´
order_detail_cols = [
    'æ³¨æ–‡ç•ªå·', 'å•†å“ç¬¦å·', 'å•†å“ã‚³ãƒ¼ãƒ‰', 'å•†å“å', 'ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼',
    'æ•°é‡','ç¨æŠœåˆè¨ˆé‡‘é¡', 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡', 'æ³¨æ–‡æ—¥', 'ä¼šå“¡ç•ªå·', 'å¹´ä»£', 'æ³¨æ–‡è€…éƒ½é“åºœçœŒ',
    'é©ç”¨ã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³','ãƒ©ã‚¤ãƒ–è³¼å…¥ãƒ•ãƒ©ã‚°', 'å¹´æœˆ','ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°åˆå›è³¼å…¥ãƒ•ãƒ©ã‚°','æ³¨æ–‡å†…ãƒãƒ¥ãƒ¼ãƒ“ãƒ³ã‚°è³¼å…¥æœ¬æ•°'
]
order_detail_summary = order_detail_summary[order_detail_cols]
order_detail_summary = order_detail_summary.sort_values('æ³¨æ–‡æ—¥', ascending=False)

monthly_category_cols = [
    'å¹´æœˆ', 'å•†å“ç¬¦å·', 'å•†å“ã‚³ãƒ¼ãƒ‰', 'å•†å“å', 'ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼',
    'æ•°é‡', 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'
]
monthly_category = monthly_category[monthly_category_cols]
monthly_category["å¹´æœˆ"] = monthly_category["å¹´æœˆ"].astype(str)

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’é–‹ã
spreadsheet = gc.open("tarte å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹")
worksheet_order = spreadsheet.worksheet("æ³¨æ–‡å•†å“æ˜ç´°ï¼ˆECï¼‰")
worksheet_category = spreadsheet.worksheet("å•†å“å®Ÿç¸¾ï¼ˆECï¼‰")

# æ³¨æ–‡å•†å“æ˜ç´°ï¼ˆECï¼‰ã«è¿½è¨˜
existing_order = get_as_dataframe(worksheet_order, evaluate_formulas=True).dropna(how='all')
combined_order = pd.concat([existing_order, order_detail_summary], ignore_index=True).drop_duplicates(subset=['æ³¨æ–‡ç•ªå·', 'å•†å“ã‚³ãƒ¼ãƒ‰'])

# å…¨ä½“ã‚’æ³¨æ–‡æ—¥ã§é™é †ã«ä¸¦ã¹ã‚‹
combined_order['æ³¨æ–‡æ—¥'] = pd.to_datetime(combined_order['æ³¨æ–‡æ—¥'], errors='coerce')
combined_order = combined_order.sort_values('æ³¨æ–‡æ—¥', ascending=False)

worksheet_order.clear()
set_with_dataframe(worksheet_order, combined_order)

# å•†å“å®Ÿç¸¾ï¼ˆECï¼‰ã‚’åŠ ç®—æ›´æ–°ã§è¿½è¨˜ã€€æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
existing_category = get_as_dataframe(worksheet_category, evaluate_formulas=True).dropna(how='all')

# ã‚‚ã—æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒç©ºãªã‚‰ã€ç©ºã®DataFrameã‚’ç”¨æ„
if existing_category.empty:
    existing_category = pd.DataFrame(columns=['å¹´æœˆ', 'å•†å“ã‚³ãƒ¼ãƒ‰', 'å•†å“ç¬¦å·',
                                              'å•†å“å', 'ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼',
                                              'ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'æ•°é‡', 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'])

# æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚‚åŒã˜
if not existing_category.empty:
    existing_category["å¹´æœˆ"] = pd.to_datetime(existing_category["å¹´æœˆ"], errors='coerce')

# æœˆæ¬¡å•†å“åˆ¥é›†è¨ˆãƒ‡ãƒ¼ã‚¿ã¨æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’åˆç®—
combined_category = pd.concat([existing_category, monthly_category], ignore_index=True)

# å¿…è¦ãªåˆ—ã‚’å‹æ•´å‚™
combined_category['å¹´æœˆ'] = pd.to_datetime(combined_category['å¹´æœˆ'], errors='coerce')
combined_category['å•†å“ã‚³ãƒ¼ãƒ‰'] = combined_category['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str)
combined_category['å•†å“ç¬¦å·'] = combined_category['å•†å“ç¬¦å·'].astype(str)

for col in ['æ•°é‡', 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡']:
    combined_category[col] = pd.to_numeric(combined_category[col], errors='coerce').fillna(0)

# å•†å“ã‚³ãƒ¼ãƒ‰å˜ä½ã§åˆç®—
aggregated = combined_category.groupby(['å¹´æœˆ', 'å•†å“ã‚³ãƒ¼ãƒ‰'], as_index=False).agg({
    'å•†å“ç¬¦å·': 'first',
    'å•†å“å': 'first',
    'ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼': 'first',
    'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼': 'first',
    'ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼': 'first',
    'æ•°é‡': 'sum',
    'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡': 'sum'
})

aggregated = aggregated.sort_values('å¹´æœˆ', ascending=False)

# ä¿å­˜
worksheet_category.clear()
set_with_dataframe(worksheet_category, aggregated)

print(f"âœ… å‡¦ç†å®Œäº†ï¼š")
print(f"ãƒ»å•†å“å®Ÿç¸¾ï¼ˆECï¼‰ï¼š{len(monthly_category):,}ä»¶ã‚’å¯¾è±¡ã«ã€æ—¢å­˜ã®åŒæœˆãƒ»åŒå•†å“ãƒ‡ãƒ¼ã‚¿ã‚’ä¸Šæ›¸ãã—ã¾ã—ãŸ")
print(f"ãƒ»æ³¨æ–‡æ˜ç´°ï¼ˆECï¼‰ï¼š{len(order_detail_summary):,}ä»¶ã‚’æ—¢å­˜æ˜ç´°ã«è¿½è¨˜ã—ã¾ã—ãŸï¼ˆæ³¨æ–‡ç•ªå·ï¼‹å•†å“ç¬¦å·ã§é‡è¤‡æ’é™¤æ¸ˆï¼‰")

"""# **ã‚¹ãƒ†ãƒƒãƒ—3: ECã®tarteé¡§å®¢ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä»Šæœˆåˆ†ã®æ³¨æ–‡ã‚’è¿½è¨˜**

âœ…â‘ customer.csv ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„
"""

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆåã¨ã‚·ãƒ¼ãƒˆå
spreadsheet_name = "tarte å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"
worksheet_name = "é¡§å®¢ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆECï¼‰"
spreadsheet = gc.open(spreadsheet_name)
worksheet = spreadsheet.worksheet(worksheet_name)

# æ—¢å­˜ã®é¡§å®¢ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆECï¼‰ã‚’å–å¾—
df_master = get_as_dataframe(worksheet, evaluate_formulas=True).dropna(how='all')

# ------------------------------------------
# 1. ä¼šå“¡æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆCSVï¼‰ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã¨èª­ã¿è¾¼ã¿
# ------------------------------------------
print("ğŸ”„ ä¼šå“¡æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„")
uploaded = files.upload()
uploaded_files = list(uploaded.keys())
members_file = next((f for f in uploaded_files if 'customer' in f.lower() and f.endswith('.csv')), None)
assert members_file, "ä¼šå“¡æƒ…å ±ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆcustomer*.csvï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“"

df_members = pd.read_csv(members_file, encoding='cp932').rename(columns=str.strip)
df_members['ç™»éŒ²æ—¥'] = pd.to_datetime(df_members['ç™»éŒ²æ—¥'], errors='coerce')

# ------------------------------------------
# 2. æ³¨æ–‡æ˜ç´°ãƒ‡ãƒ¼ã‚¿ï¼ˆorder_detail_summaryï¼‰ã‚’å‰æã¨ã—ã¦ä½¿ç”¨
# ------------------------------------------
df_orders = order_detail_summary.copy()
df_orders['æ³¨æ–‡æ—¥'] = pd.to_datetime(df_orders['æ³¨æ–‡æ—¥'], errors='coerce')

# ------------------------------------------
# 3. æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
# ------------------------------------------
for df, cols, name in [(df_master, ['ä¼šå“¡ç•ªå·', 'æ³¨æ–‡ç•ªå·'], 'é¡§å®¢ãƒã‚¹ã‚¿'),
                       (df_members, ['ä¼šå“¡ç•ªå·'], 'ä¼šå“¡æƒ…å ±'),
                       (df_orders, ['ä¼šå“¡ç•ªå·', 'æ³¨æ–‡ç•ªå·', 'å•†å“ç¬¦å·'], 'æ³¨æ–‡æ˜ç´°')]:
    for col in cols:
        if col not in df.columns:
            raise ValueError(f"âŒ {name} ã«ã‚«ãƒ©ãƒ ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {col}")

# ------------------------------------------
# 4. ä¼šå“¡æƒ…å ±ã‚’ãƒãƒ¼ã‚¸ã—ã¦ã‚«ãƒ©ãƒ ã‚’æ•´ç†
# ------------------------------------------
for df in [df_members, df_orders, df_master]:
    df['ä¼šå“¡ç•ªå·'] = pd.to_numeric(df['ä¼šå“¡ç•ªå·'], errors='coerce').astype(pd.Int64Dtype()).astype(str)

if df_members['ä¼šå“¡ç•ªå·'].duplicated().sum() > 0:
    df_members = df_members.sort_values('ç™»éŒ²æ—¥', ascending=False).drop_duplicates('ä¼šå“¡ç•ªå·')

df_orders = pd.merge(df_orders, df_members[['ä¼šå“¡ç•ªå·', 'ç™»éŒ²æ—¥']], on='ä¼šå“¡ç•ªå·', how='left')

COLUMN_ORDER = ['ä¼šå“¡ç•ªå·', 'å¹´ä»£', 'éƒ½é“åºœçœŒ', 'ä¼šå“¡ç™»éŒ²æ—¥', 'æ³¨æ–‡æ—¥', 'æ³¨æ–‡ç•ªå·',
                'å•†å“ç¬¦å·','å•†å“ã‚³ãƒ¼ãƒ‰', 'å•†å“å', 'ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼',
                'æ•°é‡', 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡', 'ãƒ©ã‚¤ãƒ–è³¼å…¥ãƒ•ãƒ©ã‚°', 'ãƒ–ãƒ©ãƒ³ãƒ‰æ–°è¦', 'ãƒ¡ã‚¾ãƒ³æ–°è¦']
df_orders_renamed = df_orders.rename(columns={'ç™»éŒ²æ—¥': 'ä¼šå“¡ç™»éŒ²æ—¥', 'æ³¨æ–‡è€…éƒ½é“åºœçœŒ': 'éƒ½é“åºœçœŒ'})
df_orders_renamed['ãƒ–ãƒ©ãƒ³ãƒ‰æ–°è¦'] = df_orders_renamed['ãƒ¡ã‚¾ãƒ³æ–°è¦'] = 0

for col in COLUMN_ORDER:
    if col not in df_orders_renamed.columns:
        df_orders_renamed[col] = None
    if col not in df_master.columns:
        df_master[col] = None

df_orders_renamed = df_orders_renamed[COLUMN_ORDER]
df_master = df_master[COLUMN_ORDER]

# 5. æ³¨æ–‡ã‚­ãƒ¼ä½œæˆã¨æ–°è¦æŠ½å‡ºãƒ»ãƒ•ãƒ©ã‚°ä»˜ä¸ (å®Œå…¨ä¿®æ­£ç‰ˆ)

df_master['æ³¨æ–‡ã‚­ãƒ¼'] = (
    df_master['æ³¨æ–‡ç•ªå·'].astype(str) + '_' +
    df_master['å•†å“ç¬¦å·'].astype(str) + '_' +
    df_master['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str)
)
df_orders_renamed['æ³¨æ–‡ã‚­ãƒ¼'] = (
    df_orders_renamed['æ³¨æ–‡ç•ªå·'].astype(str) + '_' +
    df_orders_renamed['å•†å“ç¬¦å·'].astype(str) + '_' +
    df_orders_renamed['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str)
)

æ–°è¦ã‚­ãƒ¼ = set(df_orders_renamed['æ³¨æ–‡ã‚­ãƒ¼']) - set(df_master['æ³¨æ–‡ã‚­ãƒ¼'])
df_new_orders_only = df_orders_renamed[df_orders_renamed['æ³¨æ–‡ã‚­ãƒ¼'].isin(æ–°è¦ã‚­ãƒ¼)].copy()

if len(df_new_orders_only) > 0:
    # æ—¢å­˜ã®ä¼šå“¡åˆ¥æœ€å¤æ³¨æ–‡æ—¥
    existing_first_orders = (
        df_master.groupby('ä¼šå“¡ç•ªå·')['æ³¨æ–‡æ—¥'].min()
        .reset_index().rename(columns={'æ³¨æ–‡æ—¥': 'æ—¢å­˜æœ€å¤æ³¨æ–‡æ—¥'})
    )

    # ä»Šå›è¿½åŠ åˆ†ã«çµåˆ
    df_new_orders_only = pd.merge(
        df_new_orders_only,
        existing_first_orders,
        on='ä¼šå“¡ç•ªå·',
        how='left'
    )

    # ä»Šå›æœ€å¤æ³¨æ–‡æ—¥
    df_new_orders_only['ä»Šå›æœ€å¤æ³¨æ–‡æ—¥'] = df_new_orders_only.groupby('ä¼šå“¡ç•ªå·')['æ³¨æ–‡æ—¥'].transform('min')

    # ãƒ–ãƒ©ãƒ³ãƒ‰æ–°è¦ï¼šæ—¢å­˜æœ€å¤ãŒNaT ã‹ã¤ ä»Šå›æœ€å¤
    df_new_orders_only['ãƒ–ãƒ©ãƒ³ãƒ‰æ–°è¦'] = (
        df_new_orders_only['æ—¢å­˜æœ€å¤æ³¨æ–‡æ—¥'].isna() &
        (df_new_orders_only['æ³¨æ–‡æ—¥'] == df_new_orders_only['ä»Šå›æœ€å¤æ³¨æ–‡æ—¥'])
    ).astype(int)

    # ãƒ¡ã‚¾ãƒ³æ–°è¦
    df_new_orders_only['ãƒ¡ã‚¾ãƒ³æ–°è¦'] = (
        (df_new_orders_only['æ³¨æ–‡æ—¥'] - df_new_orders_only['ä¼šå“¡ç™»éŒ²æ—¥']).dt.days <= 7
    ).fillna(False).astype(int)

    # ä¸è¦åˆ—å‰Šé™¤
    df_new_orders_only = df_new_orders_only.drop(columns=['æ—¢å­˜æœ€å¤æ³¨æ–‡æ—¥', 'ä»Šå›æœ€å¤æ³¨æ–‡æ—¥'])

    # æ–°ã—ã„ãƒã‚¹ã‚¿
    df_new_master = pd.concat([df_master, df_new_orders_only], ignore_index=True).drop_duplicates('æ³¨æ–‡ã‚­ãƒ¼', keep='last')
else:
    df_new_master = df_master.copy()

df_new_master = df_new_master.sort_values(by=['æ³¨æ–‡æ—¥', 'æ³¨æ–‡ç•ªå·', 'å•†å“ç¬¦å·']).drop(columns='æ³¨æ–‡ã‚­ãƒ¼', errors='ignore')

# ------------------------------------------
# 6. Googleã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¿½è¨˜ãƒ»ä¿å­˜
# ------------------------------------------
# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰ã®æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å–å¾—å¾Œ
existing_data = get_as_dataframe(worksheet, evaluate_formulas=True).dropna(how='all')

# æ—¥ä»˜åˆ—ã‚’ datetime å‹ã«å¤‰æ›ã—ã¦ãŠãï¼ˆâ†ã“ã‚ŒãŒé‡è¦ï¼ï¼‰
for col in ['æ³¨æ–‡æ—¥', 'ä¼šå“¡ç™»éŒ²æ—¥']:
    if col in existing_data.columns:
        existing_data[col] = pd.to_datetime(existing_data[col], errors='coerce')

# ä»¥ä¸‹ã€ã„ã¤ã‚‚é€šã‚Šçµåˆãƒ»é‡è¤‡æ’é™¤
combined_data = pd.concat([existing_data, df_new_master], ignore_index=True)

# æ³¨æ–‡ã‚­ãƒ¼ã‚’ã€Œæ³¨æ–‡ç•ªå· + å•†å“ç¬¦å· + å•†å“ã‚³ãƒ¼ãƒ‰ã€ã§ä½œæˆ
combined_data['æ³¨æ–‡ã‚­ãƒ¼'] = (
    combined_data['æ³¨æ–‡ç•ªå·'].astype(str) + '_' +
    combined_data['å•†å“ç¬¦å·'].astype(str) + '_' +
    combined_data['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str)
)

# å¿µã®ãŸã‚ã€ã“ã“ã§ã‚‚å†åº¦å‹çµ±ä¸€ï¼ˆå®‰å…¨æ€§é«˜ã‚ï¼‰
combined_data['æ³¨æ–‡æ—¥'] = pd.to_datetime(combined_data['æ³¨æ–‡æ—¥'], errors='coerce')

# æ³¨æ–‡ã‚­ãƒ¼ã§é‡è¤‡é™¤å»ï¼ˆæœ€æ–°ã®ã‚‚ã®ã‚’æ®‹ã™ï¼‰
combined_data = combined_data.sort_values('æ³¨æ–‡æ—¥', ascending=False).drop_duplicates('æ³¨æ–‡ã‚­ãƒ¼', keep='first')

# ä¸è¦ãªåˆ—ã‚’å‰Šé™¤
combined_data = combined_data.drop(columns='æ³¨æ–‡ã‚­ãƒ¼')
combined_data = combined_data.drop(columns=['åˆå›æ³¨æ–‡æ—¥'], errors='ignore')

#æ³¨æ–‡æ—¥é™é †ã§ä¸¦ã¹æ›¿ãˆ
combined_data = combined_data.sort_values('æ³¨æ–‡æ—¥', ascending=False)

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜
worksheet.clear()
set_with_dataframe(worksheet, combined_data)

print(f"âœ… ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¿½è¨˜å®Œäº†ï¼ç¾åœ¨ã®ä»¶æ•°: {len(combined_data):,}")

"""# **ã‚¹ãƒ†ãƒƒãƒ—4:** **åº—èˆ—ã®æ³¨æ–‡æ˜ç´°ã‚’æ³¨æ–‡ã€å•†å“ã”ã¨ã«é›†è¨ˆã™ã‚‹**

âœ…â‘ ZC870 æ˜ç´°å‡ºåŠ›.xlsxã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„
"""

# 1. ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
uploaded = files.upload()
uploaded_files = list(uploaded.keys())

storesales_file = next((f for f in uploaded_files if f.startswith('ZC870')), None)
assert storesales_file is not None, "å£²ä¸Šãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚"

# 2. å£²ä¸Šãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ»å‰å‡¦ç†
print("ğŸ”„ å£²ä¸Šãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ä¸­...")
ssd = pd.read_excel(storesales_file)
ssd['å¹´æœˆæ—¥'] = pd.to_datetime(ssd['å¹´æœˆæ—¥'], errors='coerce')
ssd['å•†å“ã‚³ãƒ¼ãƒ‰'] = ssd['å•†å“ç¬¦å·(7æ¡)'].astype(str)
ssd['å•†å“ç¬¦å·'] = ssd['å•†å“ç¬¦å·(7æ¡)'].astype(str).str[:4]
ssd['ç”Ÿå¹´æœˆæ—¥'] = pd.to_datetime(ssd['ç”Ÿå¹´æœˆæ—¥'], errors='coerce').dt.date
ssd = ssd.rename(columns={
    'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡': 'å‰²å¼•å¾Œåˆè¨ˆé‡‘é¡'
})

# å¹´é½¢ã¨å¹´ä»£
today = date.today()
ssd['å¹´é½¢'] = ssd['ç”Ÿå¹´æœˆæ—¥'].apply(lambda x: today.year - x.year - ((today.month, today.day) < (x.month, x.day)) if pd.notnull(x) else None)
ssd['å¹´ä»£'] = ssd['å¹´é½¢'].apply(convert_to_age_group)

# æ³¨æ–‡ãƒ¡ã‚¿æƒ…å ±
order_meta = ssd[['åº—æ¶ˆå®Ÿç¸¾ID', 'å¹´æœˆæ—¥', 'é¡§å®¢ã‚³ãƒ¼ãƒ‰', 'å¹´ä»£', 'åº—èˆ—å', 'å®¢åŒºåˆ†åç§°']].drop_duplicates('åº—æ¶ˆå®Ÿç¸¾ID')
order_meta['å¹´æœˆ'] = order_meta['å¹´æœˆæ—¥'].dt.to_period('M').astype(str)

# æ³¨æ–‡æ˜ç´°ã®é›†è¨ˆï¼ˆå•†å“ã‚³ãƒ¼ãƒ‰å˜ä½ã€å•†å“ç¬¦å·åˆ—ã¯ä¿æŒï¼‰
order_detail = ssd.groupby(['åº—æ¶ˆå®Ÿç¸¾ID', 'å•†å“ç¬¦å·', 'å•†å“ã‚³ãƒ¼ãƒ‰'], as_index=False).agg({'æ•°é‡': 'sum', 'å‰²å¼•å¾Œåˆè¨ˆé‡‘é¡': 'sum'})
order_detail = pd.merge(order_detail, order_meta, on='åº—æ¶ˆå®Ÿç¸¾ID', how='left')

# æœˆæ¬¡é›†è¨ˆï¼ˆå¹´æœˆï¼‹å•†å“ã‚³ãƒ¼ãƒ‰å˜ä½ã€å•†å“ç¬¦å·ã‚‚å‡ºåŠ›ã«æ®‹ã™ï¼‰
monthly_summary = order_detail.groupby(['å¹´æœˆ', 'å•†å“ç¬¦å·', 'å•†å“ã‚³ãƒ¼ãƒ‰'], as_index=False).agg({'æ•°é‡': 'sum', 'å‰²å¼•å¾Œåˆè¨ˆé‡‘é¡': 'sum'})

# æ³¨æ–‡æ˜ç´°ãƒ»æœˆæ¬¡å®Ÿç¸¾ã«ãƒã‚¹ã‚¿æƒ…å ±ã‚’çµåˆ
order_detail = pd.merge(order_detail, product_master_by_code, on='å•†å“ã‚³ãƒ¼ãƒ‰', how='left')
monthly_summary = pd.merge(monthly_summary, product_master_by_code, on='å•†å“ã‚³ãƒ¼ãƒ‰', how='left')

# ä¸¦ã³é †ã‚’æŒ‡å®š
desired_columns = [
    'åº—æ¶ˆå®Ÿç¸¾ID',
    'å•†å“ç¬¦å·',
    'å•†å“ã‚³ãƒ¼ãƒ‰',
    'å•†å“å',
    'ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼',
    'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼',
    'ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼',
    'æ•°é‡',
    'å‰²å¼•å¾Œåˆè¨ˆé‡‘é¡',
    'å¹´æœˆæ—¥',
    'é¡§å®¢ã‚³ãƒ¼ãƒ‰',
    'å¹´ä»£',
    'åº—èˆ—å',
    'å®¢åŒºåˆ†åç§°',
    'å¹´æœˆ'
]

# å¿…è¦ãªåˆ—ã ã‘æŠœãå‡ºã—ã¦é †åºã‚’ä¸¦ã¹ã‚‹
order_detail = order_detail.loc[:, desired_columns]

# ä¸¦ã³æ›¿ãˆ
order_detail = order_detail.sort_values('å¹´æœˆæ—¥', ascending=False)

# æœ€çµ‚å‡ºåŠ›
print("\nâœ… ãƒ‡ãƒ¼ã‚¿é›†è¨ˆå®Œäº†")
print(f"  æ³¨æ–‡æ˜ç´°ä»¶æ•°: {len(order_detail):,}")
print(f"  æœˆæ¬¡é›†è¨ˆä»¶æ•°: {len(monthly_summary):,}")

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¨ã‚·ãƒ¼ãƒˆåã‚’æŒ‡å®š
spreadsheet_name = "tarte å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"
spreadsheet = gc.open(spreadsheet_name)

# æ³¨æ–‡å•†å“æ˜ç´°ï¼ˆåº—èˆ—ï¼‰ã®è¿½è¨˜
worksheet_storeorder = spreadsheet.worksheet("æ³¨æ–‡å•†å“æ˜ç´°ï¼ˆåº—èˆ—ï¼‰")
existing_order_store = get_as_dataframe(worksheet_storeorder, evaluate_formulas=True).dropna(how='all')
combined_order_store = pd.concat([existing_order_store, order_detail], ignore_index=True).drop_duplicates(subset=['åº—æ¶ˆå®Ÿç¸¾ID', 'å•†å“ã‚³ãƒ¼ãƒ‰'])

combined_order_store['å¹´æœˆæ—¥'] = pd.to_datetime(combined_order_store['å¹´æœˆæ—¥'], errors='coerce')
combined_order_store = combined_order_store.sort_values('å¹´æœˆæ—¥', ascending=False)

worksheet_storeorder.clear()
set_with_dataframe(worksheet_storeorder, combined_order_store)

# å•†å“å®Ÿç¸¾ï¼ˆåº—èˆ—ï¼‰ã®åŠ ç®—æ›´æ–°
worksheet_storecategory = spreadsheet.worksheet("å•†å“å®Ÿç¸¾ï¼ˆåº—èˆ—ï¼‰")
existing_category_store = get_as_dataframe(worksheet_storecategory, evaluate_formulas=True).dropna(how='all')

# ç©ºãªã‚‰åˆ—æ§‹é€ ã ã‘æº–å‚™
if existing_category_store.empty:
    existing_category_store = pd.DataFrame(columns=[
        'å¹´æœˆ', 'å•†å“ã‚³ãƒ¼ãƒ‰', 'å•†å“ç¬¦å·',
        'å•†å“å', 'ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼',
        'æ•°é‡', 'å‰²å¼•å¾Œåˆè¨ˆé‡‘é¡'
    ])

# å¹´æœˆã‚’æ–‡å­—åˆ—ã«çµ±ä¸€
monthly_summary['å¹´æœˆ'] = monthly_summary['å¹´æœˆ'].astype(str)
existing_category_store['å¹´æœˆ'] = existing_category_store['å¹´æœˆ'].astype(str)

# å‹æƒãˆ
monthly_summary['å•†å“ã‚³ãƒ¼ãƒ‰'] = monthly_summary['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str)
existing_category_store['å•†å“ã‚³ãƒ¼ãƒ‰'] = existing_category_store['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str)
monthly_summary['å•†å“ç¬¦å·'] = monthly_summary['å•†å“ç¬¦å·'].astype(str)
existing_category_store['å•†å“ç¬¦å·'] = existing_category_store['å•†å“ç¬¦å·'].astype(str)

# æ•°å€¤åŒ–
for col in ['æ•°é‡', 'å‰²å¼•å¾Œåˆè¨ˆé‡‘é¡']:
    monthly_summary[col] = pd.to_numeric(monthly_summary[col], errors='coerce').fillna(0)
    existing_category_store[col] = pd.to_numeric(existing_category_store[col], errors='coerce').fillna(0)

# æ–°æ—§ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
combined_store_category = pd.concat([existing_category_store, monthly_summary], ignore_index=True)

# ã€Œå¹´æœˆ Ã— å•†å“ã‚³ãƒ¼ãƒ‰ã€ã§é›†è¨ˆ
aggregated_store = combined_store_category.groupby(['å¹´æœˆ', 'å•†å“ã‚³ãƒ¼ãƒ‰'], as_index=False).agg({
    'å•†å“ç¬¦å·': 'first',
    'å•†å“å': 'first',
    'ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼': 'first',
    'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼': 'first',
    'ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼': 'first',
    'æ•°é‡': 'sum',
    'å‰²å¼•å¾Œåˆè¨ˆé‡‘é¡': 'sum'
}).sort_values('å¹´æœˆ', ascending=False)

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¸ä¿å­˜
worksheet_storecategory.clear()
set_with_dataframe(worksheet_storecategory, aggregated_store)

print("\nâœ… ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†")

"""# **ã‚¹ãƒ†ãƒƒãƒ—5:** **åº—èˆ—ã®tarteé¡§å®¢ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä»Šæœˆåˆ†ã®æ³¨æ–‡ã‚’è¿½è¨˜**"""

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®æº–å‚™
spreadsheet_name = "tarte å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"
worksheet_name = "é¡§å®¢ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆåº—èˆ—ï¼‰"
spreadsheet = gc.open(spreadsheet_name)
worksheet_storecustomer = spreadsheet.worksheet(worksheet_name)

# æ—¢å­˜ãƒ‡ãƒ¼ã‚¿å–å¾—
df_master = get_as_dataframe(worksheet_storecustomer, evaluate_formulas=True).dropna(how='all')
df_master.columns = df_master.columns.str.strip()
df_master['å¹´æœˆæ—¥'] = pd.to_datetime(df_master['å¹´æœˆæ—¥'], errors='coerce')

# ------------------------------------------
# 1. æ³¨æ–‡åˆ¥ãƒ‡ãƒ¼ã‚¿ï¼ˆorder_detailã‚’ä½¿ç”¨ï¼‰
# ------------------------------------------
df_orders = order_detail.copy()
df_orders_renamed = df_orders.copy()

# å¹´æœˆæ—¥ãƒ»åº—èˆ—åã®è£œå®Œï¼ˆåˆ—ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿ï¼‰
if 'å¹´æœˆæ—¥' in df_orders.columns and df_orders_renamed['å¹´æœˆæ—¥'].isna().all():
    df_orders_renamed['å¹´æœˆæ—¥'] = df_orders['å¹´æœˆæ—¥']
if 'åº—èˆ—å' in df_orders.columns and df_orders_renamed['åº—èˆ—å'].isna().all():
    df_orders_renamed['åº—èˆ—å'] = df_orders['åº—èˆ—å']

# ------------------------------------------
# 2. ã‚«ãƒ©ãƒ çµ±ä¸€ã¨ä¸è¶³åˆ—è£œå®Œ
# ------------------------------------------
COLUMN_ORDER = [
    'é¡§å®¢ã‚³ãƒ¼ãƒ‰', 'å¹´ä»£', 'å¹´æœˆæ—¥', 'å®¢åŒºåˆ†åç§°', 'åº—æ¶ˆå®Ÿç¸¾ID','å•†å“ç¬¦å·',
    'å•†å“ã‚³ãƒ¼ãƒ‰','å•†å“å','ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼','ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼','ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼','æ•°é‡', 'å‰²å¼•å¾Œåˆè¨ˆé‡‘é¡', 'åº—èˆ—å', 'ãƒ–ãƒ©ãƒ³ãƒ‰æ–°è¦', 'ãƒ¡ã‚¾ãƒ³æ–°è¦'
]
df_orders_renamed['ãƒ–ãƒ©ãƒ³ãƒ‰æ–°è¦'] = 0
df_orders_renamed['ãƒ¡ã‚¾ãƒ³æ–°è¦'] = 0

for col in COLUMN_ORDER:
    if col not in df_orders_renamed.columns:
        df_orders_renamed[col] = pd.NA
    if col not in df_master.columns:
        df_master[col] = pd.NA

df_orders_renamed = df_orders_renamed.loc[:, COLUMN_ORDER]
df_master = df_master.loc[:, COLUMN_ORDER]

# é¡§å®¢ã‚³ãƒ¼ãƒ‰ã®å‹ã‚’æƒãˆã‚‹
for df in [df_master, df_orders_renamed]:
    df['é¡§å®¢ã‚³ãƒ¼ãƒ‰'] = (
        pd.to_numeric(df['é¡§å®¢ã‚³ãƒ¼ãƒ‰'], errors='coerce')
        .astype('Int64')
        .astype(str)
    )

# ------------------------------------------
# 3. æ–°è¦æ³¨æ–‡ã®æŠ½å‡º
# ------------------------------------------
# æ³¨æ–‡ã‚­ãƒ¼ã‚’ä½œæˆ
df_master['æ³¨æ–‡ã‚­ãƒ¼'] = (
    df_master['åº—æ¶ˆå®Ÿç¸¾ID'].astype(str) + '_' +
    df_master['å•†å“ç¬¦å·'].astype(str) + '_' +
    df_master['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str)
)
df_orders_renamed['æ³¨æ–‡ã‚­ãƒ¼'] = (
    df_orders_renamed['åº—æ¶ˆå®Ÿç¸¾ID'].astype(str) + '_' +
    df_orders_renamed['å•†å“ç¬¦å·'].astype(str) + '_' +
    df_orders_renamed['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str)
)

# æ–°è¦ã‚­ãƒ¼åˆ¤å®š
æ—¢å­˜æ³¨æ–‡ã‚­ãƒ¼ = set(df_master['æ³¨æ–‡ã‚­ãƒ¼'])
df_new_orders_only = df_orders_renamed[~df_orders_renamed['æ³¨æ–‡ã‚­ãƒ¼'].isin(æ—¢å­˜æ³¨æ–‡ã‚­ãƒ¼)].copy()

# ------------------------------------------
# 4. ãƒ•ãƒ©ã‚°ä»˜ä¸ï¼ˆãƒ–ãƒ©ãƒ³ãƒ‰æ–°è¦ãƒ»ãƒ¡ã‚¾ãƒ³æ–°è¦ï¼‰
# ------------------------------------------
df_all = pd.concat([df_master, df_new_orders_only], ignore_index=True)
df_all['å¹´æœˆæ—¥'] = pd.to_datetime(df_all['å¹´æœˆæ—¥'], errors='coerce')
df_all = df_all.sort_values(by=['é¡§å®¢ã‚³ãƒ¼ãƒ‰', 'å¹´æœˆæ—¥'])
df_all['åˆå›æ³¨æ–‡æ—¥'] = df_all.groupby('é¡§å®¢ã‚³ãƒ¼ãƒ‰')['å¹´æœˆæ—¥'].transform('min')

df_all['ãƒ–ãƒ©ãƒ³ãƒ‰æ–°è¦'] = (
    (df_all['å¹´æœˆæ—¥'] == df_all['åˆå›æ³¨æ–‡æ—¥']) |
    (df_all['å®¢åŒºåˆ†åç§°'] == 'ãƒ•ãƒªãƒ¼')
).replace({True: "1", False: "0"})

df_all['ãƒ¡ã‚¾ãƒ³æ–°è¦'] = df_all['å®¢åŒºåˆ†åç§°'].isin(['ãƒ•ãƒªãƒ¼', 'ã‚¨ãƒ³ãƒˆãƒªãƒ¼']).replace({True: "1", False: "0"})

# ä»Šå›è¿½åŠ ã•ã‚ŒãŸæ³¨æ–‡ã®ã¿ã«çµã‚‹
df_updated_orders_flagged = df_all[df_all['åº—æ¶ˆå®Ÿç¸¾ID'].isin(df_new_orders_only['åº—æ¶ˆå®Ÿç¸¾ID'])].copy()

# ------------------------------------------
# 5. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«è¿½è¨˜ãƒ»ä¿å­˜
# ------------------------------------------
df_new_storemaster = pd.concat([df_master, df_updated_orders_flagged], ignore_index=True).sort_values(by='å¹´æœˆæ—¥')

# âœ… æ³¨æ–‡ã”ã¨ã«è¤‡æ•°å•†å“ã‚’å«ã‚ã‚‹ãŸã‚ã€Œæ³¨æ–‡ã‚­ãƒ¼ï¼åº—æ¶ˆå®Ÿç¸¾ID + å•†å“ç¬¦å·ã€ã§é‡è¤‡ã‚’å®šç¾©ã™ã‚‹
combined_store_customer = pd.concat([df_master, df_updated_orders_flagged], ignore_index=True)

# æ³¨æ–‡ã‚­ãƒ¼ã‚’ä½œæˆï¼ˆæ³¨æ–‡IDï¼‹å•†å“ç¬¦å·ï¼‹å•†å“ã‚³ãƒ¼ãƒ‰ï¼‰
combined_store_customer['æ³¨æ–‡ã‚­ãƒ¼'] = (
    combined_store_customer['åº—æ¶ˆå®Ÿç¸¾ID'].astype(str) + '_' +
    combined_store_customer['å•†å“ç¬¦å·'].astype(str) + '_' +
    combined_store_customer['å•†å“ã‚³ãƒ¼ãƒ‰'].astype(str)
)

# æ³¨æ–‡ã‚­ãƒ¼ã§é‡è¤‡æ’é™¤ï¼ˆå•†å“ã”ã¨ã«1è¡Œã¯æ®‹ã™ï¼‰
combined_store_customer = combined_store_customer.sort_values('å¹´æœˆæ—¥', ascending=False)
combined_store_customer = combined_store_customer.drop_duplicates(subset='æ³¨æ–‡ã‚­ãƒ¼', keep='first')

# æ³¨æ–‡ã‚­ãƒ¼åˆ—ã‚’å‰Šé™¤
combined_store_customer = combined_store_customer.drop(columns='æ³¨æ–‡ã‚­ãƒ¼', errors='ignore')
combined_store_customer = combined_store_customer.drop(columns=['åˆå›æ³¨æ–‡æ—¥'], errors='ignore')

#å¹´æœˆæ—¥é™é †ã§ä¸¦ã³æ›¿ãˆ
combined_store_customer = combined_store_customer.sort_values('å¹´æœˆæ—¥', ascending=False)

# ä¿å­˜
worksheet_storecustomer.clear()
set_with_dataframe(worksheet_storecustomer, combined_store_customer)

print(f"\nâœ… tarteé¡§å®¢ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ï¼ˆåº—èˆ—ï¼‰è¿½è¨˜å®Œäº†ï¼ä»¶æ•°: {len(combined_store_customer):,}")

"""# **ã‚¹ãƒ†ãƒƒãƒ—6:** **åº—èˆ—ã¨ECã®å•†å“å®Ÿç¸¾ã‚’åˆç®—é›†è¨ˆ**"""

# ============================================
# âœ… åº—èˆ—ãƒ‡ãƒ¼ã‚¿ã¨ECãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™
# ============================================

# ã‚³ãƒ”ãƒ¼
åº—èˆ—_df = aggregated_store.copy()
EC_df = aggregated.copy()

# åº—èˆ—ã®é‡‘é¡åˆ—ã‚’ECã«åˆã‚ã›ã‚‹
åº—èˆ—_df = åº—èˆ—_df.rename(columns={'å‰²å¼•å¾Œåˆè¨ˆé‡‘é¡': 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'})

# ã‚«ãƒ³ãƒé™¤å»ãƒ»å¹´æœˆã‚’datetimeãƒ»æ•°å€¤åŒ–
for df in [åº—èˆ—_df, EC_df]:
    df['å¹´æœˆ'] = pd.to_datetime(df['å¹´æœˆ'], format='%Y-%m', errors='coerce')
    df['ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'] = df['ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'].astype(str).str.replace(',', '', regex=False)
    df['ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'] = pd.to_numeric(df['ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'], errors='coerce')
    df['æ•°é‡'] = pd.to_numeric(df['æ•°é‡'], errors='coerce')

# ============================================
# âœ… ä¸¡ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
# ============================================
combined_df = pd.concat([åº—èˆ—_df, EC_df], ignore_index=True)

# ============================================
# âœ… å•†å“ã‚³ãƒ¼ãƒ‰å˜ä½ã§é›†è¨ˆ
# ============================================
aggregated_df = combined_df.groupby(
    ['å¹´æœˆ', 'å•†å“ã‚³ãƒ¼ãƒ‰'],
    as_index=False
).agg({
    'æ•°é‡': 'sum',
    'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡': 'sum'
})

# å¿µã®ãŸã‚å¹´æœˆã‚’datetime
aggregated_df['å¹´æœˆ'] = pd.to_datetime(aggregated_df['å¹´æœˆ'], format='%Y-%m')

# ============================================
# âœ… å•†å“ãƒã‚¹ã‚¿ã‚’å•†å“ã‚³ãƒ¼ãƒ‰ã§JOIN
# ============================================
# category_master ã‚’äº‹å‰ã«èª­ã¿è¾¼ã‚“ã§ã„ã‚‹æƒ³å®š
product_info_cols = ['å•†å“ã‚³ãƒ¼ãƒ‰', 'å•†å“ç¬¦å·', 'å•†å“å', 'ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼']
product_master_by_code = category_master[product_info_cols].drop_duplicates(subset='å•†å“ã‚³ãƒ¼ãƒ‰', keep='first')

aggregated_df = pd.merge(
    aggregated_df,
    product_master_by_code,
    on='å•†å“ã‚³ãƒ¼ãƒ‰',
    how='left'
)

# ============================================
# âœ… ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå–å¾—
# ============================================
spreadsheet_name = "tarte å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹"
spreadsheet = gc.open(spreadsheet_name)
worksheet_totalproduct = spreadsheet.worksheet("å•†å“å®Ÿç¸¾ï¼ˆåˆç®—ï¼‰")

# ============================================
# âœ… æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
# ============================================
existing_df = get_as_dataframe(worksheet_totalproduct, evaluate_formulas=True).dropna(how='all')

if existing_df.empty:
    existing_df = pd.DataFrame(columns=aggregated_df.columns)

# å¹´æœˆã‚’datetime
existing_df['å¹´æœˆ'] = pd.to_datetime(existing_df['å¹´æœˆ'], errors='coerce')

# ============================================
# âœ… æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã¨æ–°ãƒ‡ãƒ¼ã‚¿ã‚’ã‚­ãƒ¼ã§ãƒãƒ¼ã‚¸ï¼ˆä¸Šæ›¸ãï¼‰
# ============================================
keys = ['å¹´æœˆ', 'å•†å“ã‚³ãƒ¼ãƒ‰']

merged_df = pd.merge(
    existing_df,
    aggregated_df,
    on=keys,
    how='outer',
    suffixes=('_old', '')
)

# æ•°é‡ãƒ»é‡‘é¡ã‚’æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§ä¸Šæ›¸ã
merged_df['æ•°é‡'] = merged_df['æ•°é‡'].combine_first(merged_df['æ•°é‡_old'])
merged_df['ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'] = merged_df['ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'].combine_first(merged_df['ç¨æŠœå‰²å¼•å¾Œé‡‘é¡_old'])

# å•†å“ç¬¦å·ãƒ»å•†å“åãƒ»ã‚«ãƒ†ã‚´ãƒªãƒ¼ã‚‚æ–°ãƒ‡ãƒ¼ã‚¿ã§ä¸Šæ›¸ã
for col in ['å•†å“ç¬¦å·', 'å•†å“å', 'ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼']:
    merged_df[col] = merged_df[col].combine_first(merged_df[f'{col}_old'])

# ä¸è¦ãªæ—§ã‚«ãƒ©ãƒ ã‚’å‰Šé™¤
merged_df = merged_df.drop(columns=[c for c in merged_df.columns if c.endswith('_old')])

# ä¸¦ã¹æ›¿ãˆ
merged_df = merged_df.sort_values(['å¹´æœˆ', 'å•†å“ã‚³ãƒ¼ãƒ‰'], ascending=[False, True])

# ============================================
# âœ… è¡¨ç¤ºç”¨æ•´å½¢
# ============================================
display_df = merged_df.copy()
display_df['ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'] = display_df['ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'].round(0).astype(int).map('{:,}'.format)

# è¡¨ç¤º
display(display_df[[
    'å¹´æœˆ', 'å•†å“ç¬¦å·', 'å•†å“ã‚³ãƒ¼ãƒ‰', 'å•†å“å',
    'ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼', 'ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼',
    'æ•°é‡', 'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'
]].head())

# ============================================
# âœ… ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«ä¿å­˜
# ============================================
worksheet_totalproduct.clear()

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆç”¨ã«åˆ—ã‚’ä¸¦ã¹æ›¿ãˆ
merged_df = merged_df[[
    'å¹´æœˆ',
    'å•†å“ã‚³ãƒ¼ãƒ‰',
    'å•†å“ç¬¦å·',
    'å•†å“å',
    'ãƒ¡ã‚¤ãƒ³ã‚«ãƒ†ã‚´ãƒªãƒ¼',
    'ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼',
    'ã‚µãƒ–ã‚µãƒ–ã‚«ãƒ†ã‚´ãƒªãƒ¼',
    'æ•°é‡',
    'ç¨æŠœå‰²å¼•å¾Œé‡‘é¡'
]]

set_with_dataframe(worksheet_totalproduct, merged_df)

print("\nâœ… é›†è¨ˆã¨ä¿å­˜ãŒå®Œäº†ã—ã¾ã—ãŸï¼")